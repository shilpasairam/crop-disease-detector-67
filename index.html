<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Crop Disease Detector</title>
  <!-- Load TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <style>
    body {
      font-family: 'Segoe UI', Arial, sans-serif;
      background: linear-gradient(135deg, #74ebd5 0%, #ACB6E5 100%);
      color: #333;
      text-align: center;
      margin: 0;
      padding: 0;
    }
    h1 {
      margin-top: 40px;
      font-size: 2.5em;
      color: #fff;
      text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    .container {
      margin: 50px auto;
      padding: 30px;
      background: rgba(255, 255, 255, 0.9);
      border-radius: 12px;
      width: 80%;
      max-width: 600px;
      box-shadow: 0 8px 20px rgba(0,0,0,0.2);
    }
    button {
      background: #ff6f61;
      border: none;
      padding: 12px 24px;
      font-size: 1.1em;
      color: #fff;
      border-radius: 8px;
      cursor: pointer;
      transition: background 0.3s ease;
      margin: 10px;
    }
    button:hover { background: #ff3b2e; }
    video {
      margin-top: 20px;
      border: 4px solid #ff6f61;
      border-radius: 12px;
      width: 100%;
      max-width: 500px;
    }
    #result {
      margin-top: 20px;
      font-size: 1.5em;
      font-weight: bold;
      color: #333;
    }
  </style>
</head>
<body>
  <h1>üå± Crop Disease Detector</h1>

  <div class="container">
    <p>Place your crop leaf in front of the camera to detect if it‚Äôs healthy or unhealthy.</p>
    <button onclick="startCamera()">Start Camera</button>
    <button onclick="makePrediction()">Predict</button>
    <video id="video" autoplay playsinline></video>
    <div id="result"></div>
  </div>

  <script>
    let model;

    // Load the model from root
    async function loadModel() {
      try {
        model = await tf.loadLayersModel('model.json'); 
        console.log("‚úÖ Model loaded successfully");
      } catch (error) {
        console.error("‚ùå Error loading model:", error);
      }
    }

    // Start camera
    async function startCamera() {
      const video = document.getElementById('video');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        alert("Camera access blocked. Please allow camera.");
      }
    }

    // Make prediction
    async function makePrediction() {
      if (!model) {
        alert("Model not loaded yet!");
        return;
      }
      const video = document.getElementById('video');

      // Capture frame from video
      const tensor = tf.browser.fromPixels(video)
        .resizeNearestNeighbor([224, 224]) // adjust if your model expects different size
        .toFloat()
        .expandDims();

      const prediction = model.predict(tensor);
      const result = await prediction.data();

      // Example: binary classification [Healthy, Unhealthy]
      const healthyProb = result[0];
      const unhealthyProb = result[1];

      let output = "";
      if (healthyProb > unhealthyProb) {
        output = "‚úÖ Leaf is Healthy";
      } else {
        output = "‚ö†Ô∏è Leaf is Unhealthy";
      }

      document.getElementById('result').innerText = output;
    }

    // Load model on page start
    loadModel();
  </script>
</body>
</html>
